{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MCDA Walkthrough Tutorial\n",
        "## Multi-Criteria Decision Analysis for Benefit-Risk Assessment\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nexvigilant/nv-BR-toolkit/blob/main/notebooks/MCDA_Walkthrough_Tutorial.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "### \u26a0\ufe0f EDUCATIONAL USE ONLY\n",
        "\n",
        "**This notebook is provided strictly for educational and instructional purposes.**\n",
        "- Do NOT use for regulatory decision-making\n",
        "- Do NOT use as a substitute for internal SOPs\n",
        "- All data in this notebook is **simulated/hypothetical**\n",
        "\n",
        "---\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "After completing this notebook, you will be able to:\n",
        "\n",
        "1. **Explain** the MCDA methodology and when to use it\n",
        "2. **Define** criteria and assign weights using swing weighting\n",
        "3. **Score** treatment options against defined criteria\n",
        "4. **Calculate** weighted preference scores\n",
        "5. **Perform** sensitivity analysis on weights\n",
        "6. **Visualize** MCDA results for stakeholder communication\n",
        "\n",
        "---\n",
        "\n",
        "### Background: What is MCDA?\n",
        "\n",
        "**Multi-Criteria Decision Analysis (MCDA)** is a structured approach for:\n",
        "\n",
        "- **Explicitly weighing** multiple outcomes based on their relative importance\n",
        "- **Integrating** stakeholder preferences into benefit-risk decisions\n",
        "- **Comparing** treatment options using a single composite score\n",
        "- **Exploring** how conclusions change with different value judgments\n",
        "\n",
        "**When to use MCDA:**\n",
        "- Multiple stakeholders with potentially different priorities\n",
        "- Need to make value trade-offs explicit\n",
        "- Regulatory submissions requiring quantitative B-R\n",
        "- Patient preference integration\n",
        "\n",
        "**Reference:** CIOMS Working Group XII Report, Chapter 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install and import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (uncomment if running in Colab)\n",
        "# !pip install pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.precision', 2)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "print(\"\u2705 Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MCDA Framework Overview\n",
        "\n",
        "MCDA follows a structured 5-step process:\n",
        "\n",
        "```\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502   1. DEFINE    \u2502 \u2192 \u2502   2. WEIGHT    \u2502 \u2192 \u2502   3. SCORE     \u2502 \u2192 \u2502  4. CALCULATE  \u2502 \u2192 \u2502  5. ANALYZE   \u2502\n",
        "\u2502   CRITERIA     \u2502    \u2502   CRITERIA     \u2502    \u2502   OPTIONS      \u2502    \u2502  WEIGHTED SUM  \u2502    \u2502  SENSITIVITY  \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "```\n",
        "\n",
        "Let's work through each step with a **hypothetical oncology drug comparison**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case Study: First-Line NSCLC Treatment\n",
        "\n",
        "We're comparing three treatment options for first-line advanced non-small cell lung cancer (NSCLC):\n",
        "\n",
        "| Treatment | Description |\n",
        "|-----------|-------------|\n",
        "| **NEXONC** | Novel PD-1 inhibitor + chemotherapy |\n",
        "| **Standard Chemo** | Platinum-based doublet chemotherapy |\n",
        "| **Best Supportive Care** | Symptom management only |\n",
        "\n",
        "**Note:** All data is hypothetical for educational purposes only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Define Criteria\n",
        "\n",
        "Identify the key benefit and risk criteria for comparison.\n",
        "\n",
        "### Criteria Selection Principles\n",
        "- **Complete**: Cover all relevant outcomes\n",
        "- **Non-redundant**: Avoid double-counting\n",
        "- **Measurable**: Each criterion can be quantified\n",
        "- **Preference-independent**: Preferences on one don't depend on others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define criteria with categories\n",
        "criteria = {\n",
        "    'Overall Survival': {\n",
        "        'category': 'Benefit',\n",
        "        'description': 'Median overall survival (months)',\n",
        "        'direction': 'higher_better',\n",
        "        'unit': 'months'\n",
        "    },\n",
        "    'Progression-Free Survival': {\n",
        "        'category': 'Benefit',\n",
        "        'description': 'Median PFS (months)',\n",
        "        'direction': 'higher_better',\n",
        "        'unit': 'months'\n",
        "    },\n",
        "    'Tumor Response': {\n",
        "        'category': 'Benefit',\n",
        "        'description': 'Objective response rate (%)',\n",
        "        'direction': 'higher_better',\n",
        "        'unit': '%'\n",
        "    },\n",
        "    'Grade 3-4 AEs': {\n",
        "        'category': 'Risk',\n",
        "        'description': 'Serious adverse event rate (%)',\n",
        "        'direction': 'lower_better',\n",
        "        'unit': '%'\n",
        "    },\n",
        "    'Quality of Life': {\n",
        "        'category': 'Benefit',\n",
        "        'description': 'Maintained/improved QoL (%)',\n",
        "        'direction': 'higher_better',\n",
        "        'unit': '%'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display criteria\n",
        "print(\"MCDA CRITERIA\")\n",
        "print(\"=\" * 60)\n",
        "for name, info in criteria.items():\n",
        "    emoji = \"\ud83d\udfe2\" if info['category'] == 'Benefit' else \"\ud83d\udd34\"\n",
        "    print(f\"{emoji} {name} ({info['category']})\")\n",
        "    print(f\"   {info['description']}\")\n",
        "    print(f\"   Direction: {info['direction'].replace('_', ' ')}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Assign Weights\n",
        "\n",
        "Weights reflect the **relative importance** of each criterion. Several methods exist:\n",
        "\n",
        "| Method | Description | Complexity |\n",
        "|--------|-------------|------------|\n",
        "| **Equal Weights** | All criteria weighted equally | Low |\n",
        "| **Direct Rating** | Stakeholders rate importance 1-100 | Low |\n",
        "| **Swing Weighting** | Based on range of possible outcomes | Medium |\n",
        "| **DCE-Derived** | From discrete choice experiments | High |\n",
        "\n",
        "### Swing Weighting Method\n",
        "\n",
        "Ask: *\"If all criteria were at their worst level, which criterion would you most want to swing to its best level?\"*\n",
        "\n",
        "The most important swing gets 100 points. Others are rated relative to this anchor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def swing_weighting(swing_points: Dict[str, float]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Convert swing points to normalized weights (summing to 1.0).\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    swing_points : dict\n",
        "        Raw swing points for each criterion (0-100 scale)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Normalized weights\n",
        "    \"\"\"\n",
        "    total = sum(swing_points.values())\n",
        "    return {k: v / total for k, v in swing_points.items()}\n",
        "\n",
        "# Example: Oncologist panel swing weights\n",
        "swing_points = {\n",
        "    'Overall Survival': 100,           # Anchor - most important\n",
        "    'Progression-Free Survival': 55,   # 55% as important as OS\n",
        "    'Tumor Response': 30,              # Surrogate, less weight\n",
        "    'Grade 3-4 AEs': 70,               # Safety is critical\n",
        "    'Quality of Life': 45              # Patient-centric\n",
        "}\n",
        "\n",
        "weights = swing_weighting(swing_points)\n",
        "\n",
        "# Display weights\n",
        "print(\"CRITERIA WEIGHTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"{'Criterion':<30} {'Swing':>8} {'Weight':>10}\")\n",
        "print(\"-\" * 50)\n",
        "for criterion, swing in swing_points.items():\n",
        "    weight = weights[criterion]\n",
        "    bar = \"\u2588\" * int(weight * 40)\n",
        "    print(f\"{criterion:<30} {swing:>8} {weight:>10.1%} {bar}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'TOTAL':<30} {sum(swing_points.values()):>8} {sum(weights.values()):>10.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udca1 Practice Exercise\n",
        "\n",
        "**Question:** A patient advocacy group might assign different swing points. How might their weights differ?\n",
        "\n",
        "<details>\n",
        "<summary>Click for discussion</summary>\n",
        "\n",
        "Patients might:\n",
        "- Increase **Quality of Life** weight (daily experience matters)\n",
        "- Decrease **Tumor Response** weight (surrogate, not directly felt)\n",
        "- Value **Grade 3-4 AEs** even higher (toxicity impacts daily life)\n",
        "\n",
        "This illustrates why capturing **multiple stakeholder perspectives** is valuable in MCDA.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Score Treatment Options\n",
        "\n",
        "For each treatment, we need raw data on each criterion, then convert to a **0-100 score scale**.\n",
        "\n",
        "### Scoring Methods\n",
        "\n",
        "**Linear interpolation** (most common):\n",
        "```\n",
        "Score = 100 \u00d7 (Value - Worst) / (Best - Worst)\n",
        "```\n",
        "\n",
        "Where:\n",
        "- `Best` = best plausible value (score = 100)\n",
        "- `Worst` = worst plausible value (score = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Raw clinical data (hypothetical)\n",
        "raw_data = pd.DataFrame({\n",
        "    'Treatment': ['NEXONC', 'Standard Chemo', 'Best Supportive Care'],\n",
        "    'Overall Survival': [22.0, 14.0, 8.0],          # months\n",
        "    'Progression-Free Survival': [10.5, 5.5, 2.0],  # months\n",
        "    'Tumor Response': [52, 28, 5],                  # %\n",
        "    'Grade 3-4 AEs': [58, 52, 15],                  # % (lower is better)\n",
        "    'Quality of Life': [62, 48, 70]                 # % maintained/improved\n",
        "})\n",
        "\n",
        "print(\"RAW CLINICAL DATA\")\n",
        "print(\"=\" * 70)\n",
        "print(raw_data.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def score_criterion(values: np.array, direction: str, \n",
        "                    best: float = None, worst: float = None) -> np.array:\n",
        "    \"\"\"\n",
        "    Convert raw values to 0-100 scores using linear interpolation.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    values : array\n",
        "        Raw values for each treatment\n",
        "    direction : str\n",
        "        'higher_better' or 'lower_better'\n",
        "    best : float, optional\n",
        "        Best plausible value (defaults to max/min of data)\n",
        "    worst : float, optional\n",
        "        Worst plausible value (defaults to min/max of data)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    array : Scores on 0-100 scale\n",
        "    \"\"\"\n",
        "    values = np.array(values)\n",
        "    \n",
        "    if direction == 'higher_better':\n",
        "        best = best if best is not None else values.max()\n",
        "        worst = worst if worst is not None else values.min()\n",
        "        scores = 100 * (values - worst) / (best - worst)\n",
        "    else:  # lower_better\n",
        "        best = best if best is not None else values.min()\n",
        "        worst = worst if worst is not None else values.max()\n",
        "        scores = 100 * (worst - values) / (worst - best)\n",
        "    \n",
        "    return np.clip(scores, 0, 100)\n",
        "\n",
        "# Score all criteria\n",
        "scored_data = raw_data.copy()\n",
        "\n",
        "for criterion, info in criteria.items():\n",
        "    scored_data[criterion] = score_criterion(\n",
        "        raw_data[criterion].values,\n",
        "        info['direction']\n",
        "    )\n",
        "\n",
        "print(\"SCORED DATA (0-100 scale)\")\n",
        "print(\"=\" * 70)\n",
        "print(scored_data.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Calculate Weighted Scores\n",
        "\n",
        "The **weighted preference score** for each treatment is:\n",
        "\n",
        "$$\n",
        "\\text{Total Score} = \\sum_{i=1}^{n} w_i \\times s_i\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $w_i$ = weight for criterion $i$\n",
        "- $s_i$ = score for criterion $i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_weighted_scores(scored_df: pd.DataFrame, \n",
        "                             weights: Dict[str, float],\n",
        "                             treatment_col: str = 'Treatment') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate weighted MCDA scores for each treatment.\n",
        "    \n",
        "    Returns DataFrame with weighted contributions and totals.\n",
        "    \"\"\"\n",
        "    results = scored_df[[treatment_col]].copy()\n",
        "    \n",
        "    # Calculate weighted score for each criterion\n",
        "    for criterion, weight in weights.items():\n",
        "        col_name = f\"{criterion} (w={weight:.1%})\"\n",
        "        results[col_name] = scored_df[criterion] * weight\n",
        "    \n",
        "    # Calculate total\n",
        "    score_cols = [c for c in results.columns if c != treatment_col]\n",
        "    results['TOTAL SCORE'] = results[score_cols].sum(axis=1)\n",
        "    \n",
        "    return results.sort_values('TOTAL SCORE', ascending=False)\n",
        "\n",
        "# Calculate results\n",
        "mcda_results = calculate_weighted_scores(scored_data, weights)\n",
        "\n",
        "print(\"MCDA WEIGHTED SCORES\")\n",
        "print(\"=\" * 90)\n",
        "print(mcda_results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_mcda_summary(mcda_results: pd.DataFrame, weights: Dict[str, float]):\n",
        "    \"\"\"\n",
        "    Display formatted MCDA results summary.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MCDA BENEFIT-RISK SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for idx, row in mcda_results.iterrows():\n",
        "        treatment = row['Treatment']\n",
        "        total = row['TOTAL SCORE']\n",
        "        bar_len = int(total / 2)\n",
        "        bar = \"\u2588\" * bar_len + \"\u2591\" * (50 - bar_len)\n",
        "        \n",
        "        print(f\"\\n{treatment}\")\n",
        "        print(f\"  [{bar}] {total:.1f}/100\")\n",
        "        \n",
        "        # Show contribution breakdown\n",
        "        for criterion in weights.keys():\n",
        "            col = [c for c in mcda_results.columns if criterion in c][0]\n",
        "            contribution = row[col]\n",
        "            mini_bar = \"\u2588\" * int(contribution / 2)\n",
        "            print(f\"    {criterion[:20]:<20}: +{contribution:.1f} {mini_bar}\")\n",
        "    \n",
        "    # Winner\n",
        "    winner = mcda_results.iloc[0]\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"\u2705 PREFERRED OPTION: {winner['Treatment']}\")\n",
        "    print(f\"   Total Score: {winner['TOTAL SCORE']:.1f}/100\")\n",
        "    \n",
        "    # Margin\n",
        "    if len(mcda_results) > 1:\n",
        "        second = mcda_results.iloc[1]\n",
        "        margin = winner['TOTAL SCORE'] - second['TOTAL SCORE']\n",
        "        print(f\"   Margin over {second['Treatment']}: +{margin:.1f} points\")\n",
        "\n",
        "display_mcda_summary(mcda_results, weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Sensitivity Analysis\n",
        "\n",
        "**Critical question:** How robust is our conclusion to changes in weights?\n",
        "\n",
        "Sensitivity analysis tests whether the preferred option changes under:\n",
        "- Different stakeholder perspectives\n",
        "- Uncertainty in weight elicitation\n",
        "- Extreme scenarios (e.g., \"safety-first\" vs \"efficacy-first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_way_sensitivity(scored_df: pd.DataFrame, \n",
        "                       base_weights: Dict[str, float],\n",
        "                       vary_criterion: str,\n",
        "                       weight_range: np.array = np.linspace(0, 0.6, 13)) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Perform one-way sensitivity analysis on a single criterion's weight.\n",
        "    \n",
        "    Redistributes weight proportionally among other criteria.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    other_criteria = [c for c in base_weights.keys() if c != vary_criterion]\n",
        "    base_other_sum = sum(base_weights[c] for c in other_criteria)\n",
        "    \n",
        "    for new_weight in weight_range:\n",
        "        # Redistribute remaining weight proportionally\n",
        "        remaining = 1.0 - new_weight\n",
        "        test_weights = {vary_criterion: new_weight}\n",
        "        for c in other_criteria:\n",
        "            test_weights[c] = remaining * (base_weights[c] / base_other_sum)\n",
        "        \n",
        "        # Calculate scores\n",
        "        for _, row in scored_df.iterrows():\n",
        "            total = sum(row[c] * test_weights[c] for c in test_weights.keys())\n",
        "            results.append({\n",
        "                'Weight': new_weight,\n",
        "                'Treatment': row['Treatment'],\n",
        "                'Score': total\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Sensitivity on Safety weight\n",
        "sensitivity_results = one_way_sensitivity(\n",
        "    scored_data, weights, 'Grade 3-4 AEs'\n",
        ")\n",
        "\n",
        "print(\"One-Way Sensitivity: Varying 'Grade 3-4 AEs' Weight\")\n",
        "print(\"=\" * 50)\n",
        "pivot = sensitivity_results.pivot(index='Weight', columns='Treatment', values='Score')\n",
        "print(pivot.round(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_sensitivity(sensitivity_df: pd.DataFrame, \n",
        "                    base_weight: float,\n",
        "                    criterion_name: str):\n",
        "    \"\"\"\n",
        "    Plot one-way sensitivity analysis results.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    colors = {'NEXONC': '#2ecc71', 'Standard Chemo': '#3498db', \n",
        "              'Best Supportive Care': '#e74c3c'}\n",
        "    \n",
        "    for treatment in sensitivity_df['Treatment'].unique():\n",
        "        data = sensitivity_df[sensitivity_df['Treatment'] == treatment]\n",
        "        ax.plot(data['Weight'], data['Score'], \n",
        "                label=treatment, color=colors.get(treatment, 'gray'),\n",
        "                linewidth=2, marker='o', markersize=4)\n",
        "    \n",
        "    # Mark base case\n",
        "    ax.axvline(x=base_weight, color='red', linestyle='--', \n",
        "               label=f'Base case ({base_weight:.0%})', alpha=0.7)\n",
        "    \n",
        "    ax.set_xlabel(f'Weight on {criterion_name}', fontsize=12)\n",
        "    ax.set_ylabel('Total MCDA Score', fontsize=12)\n",
        "    ax.set_title(f'Sensitivity Analysis: {criterion_name} Weight', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='best')\n",
        "    ax.set_xlim(0, 0.6)\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "fig = plot_sensitivity(sensitivity_results, weights['Grade 3-4 AEs'], 'Grade 3-4 AEs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scenario_analysis(scored_df: pd.DataFrame, \n",
        "                     scenarios: Dict[str, Dict[str, float]]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compare MCDA results across multiple weight scenarios.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for scenario_name, scenario_weights in scenarios.items():\n",
        "        # Normalize weights\n",
        "        total = sum(scenario_weights.values())\n",
        "        norm_weights = {k: v/total for k, v in scenario_weights.items()}\n",
        "        \n",
        "        for _, row in scored_df.iterrows():\n",
        "            total_score = sum(row[c] * norm_weights[c] for c in norm_weights.keys())\n",
        "            results.append({\n",
        "                'Scenario': scenario_name,\n",
        "                'Treatment': row['Treatment'],\n",
        "                'Score': total_score\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Define scenarios\n",
        "scenarios = {\n",
        "    'Base Case (Clinical)': swing_points,\n",
        "    'Efficacy-Focused': {\n",
        "        'Overall Survival': 100,\n",
        "        'Progression-Free Survival': 80,\n",
        "        'Tumor Response': 60,\n",
        "        'Grade 3-4 AEs': 30,\n",
        "        'Quality of Life': 30\n",
        "    },\n",
        "    'Safety-Focused': {\n",
        "        'Overall Survival': 60,\n",
        "        'Progression-Free Survival': 40,\n",
        "        'Tumor Response': 20,\n",
        "        'Grade 3-4 AEs': 100,\n",
        "        'Quality of Life': 80\n",
        "    },\n",
        "    'Patient-Centric': {\n",
        "        'Overall Survival': 80,\n",
        "        'Progression-Free Survival': 50,\n",
        "        'Tumor Response': 20,\n",
        "        'Grade 3-4 AEs': 70,\n",
        "        'Quality of Life': 100\n",
        "    },\n",
        "    'Equal Weights': {\n",
        "        'Overall Survival': 100,\n",
        "        'Progression-Free Survival': 100,\n",
        "        'Tumor Response': 100,\n",
        "        'Grade 3-4 AEs': 100,\n",
        "        'Quality of Life': 100\n",
        "    }\n",
        "}\n",
        "\n",
        "scenario_results = scenario_analysis(scored_data, scenarios)\n",
        "\n",
        "# Display results\n",
        "print(\"SCENARIO ANALYSIS RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "pivot = scenario_results.pivot(index='Scenario', columns='Treatment', values='Score')\n",
        "pivot['Preferred'] = pivot.idxmax(axis=1)\n",
        "print(pivot.round(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_scenario_comparison(scenario_df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Create grouped bar chart comparing scenarios.\n",
        "    \"\"\"\n",
        "    pivot = scenario_df.pivot(index='Scenario', columns='Treatment', values='Score')\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    x = np.arange(len(pivot.index))\n",
        "    width = 0.25\n",
        "    \n",
        "    colors = {'NEXONC': '#2ecc71', 'Standard Chemo': '#3498db', \n",
        "              'Best Supportive Care': '#e74c3c'}\n",
        "    \n",
        "    for i, treatment in enumerate(pivot.columns):\n",
        "        bars = ax.bar(x + i*width, pivot[treatment], width, \n",
        "                      label=treatment, color=colors.get(treatment, 'gray'))\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{height:.0f}',\n",
        "                       xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                       xytext=(0, 3), textcoords='offset points',\n",
        "                       ha='center', va='bottom', fontsize=8)\n",
        "    \n",
        "    ax.set_xlabel('Scenario', fontsize=12)\n",
        "    ax.set_ylabel('MCDA Score', fontsize=12)\n",
        "    ax.set_title('MCDA Results Across Weight Scenarios', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x + width)\n",
        "    ax.set_xticklabels(pivot.index, rotation=15, ha='right')\n",
        "    ax.legend(loc='upper right')\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.grid(True, axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "fig = plot_scenario_comparison(scenario_results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualize Results\n",
        "\n",
        "Different visualizations serve different audiences and purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_stacked_contributions(mcda_results: pd.DataFrame, \n",
        "                               weights: Dict[str, float],\n",
        "                               criteria_info: Dict):\n",
        "    \"\"\"\n",
        "    Create stacked bar chart showing criterion contributions.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    treatments = mcda_results['Treatment'].values\n",
        "    y_pos = np.arange(len(treatments))\n",
        "    \n",
        "    # Colors for criteria\n",
        "    benefit_color = plt.cm.Greens(np.linspace(0.4, 0.8, 4))\n",
        "    risk_color = plt.cm.Reds(np.linspace(0.4, 0.6, 1))\n",
        "    \n",
        "    colors = []\n",
        "    b_idx, r_idx = 0, 0\n",
        "    for criterion in weights.keys():\n",
        "        if criteria_info[criterion]['category'] == 'Benefit':\n",
        "            colors.append(benefit_color[b_idx])\n",
        "            b_idx += 1\n",
        "        else:\n",
        "            colors.append(risk_color[r_idx])\n",
        "            r_idx += 1\n",
        "    \n",
        "    # Plot stacked bars\n",
        "    left = np.zeros(len(treatments))\n",
        "    for i, criterion in enumerate(weights.keys()):\n",
        "        col = [c for c in mcda_results.columns if criterion in c][0]\n",
        "        values = mcda_results[col].values\n",
        "        ax.barh(y_pos, values, left=left, label=criterion, \n",
        "                color=colors[i], edgecolor='white', linewidth=0.5)\n",
        "        left += values\n",
        "    \n",
        "    # Add total score labels\n",
        "    for i, total in enumerate(mcda_results['TOTAL SCORE']):\n",
        "        ax.text(total + 1, i, f'{total:.1f}', va='center', fontweight='bold')\n",
        "    \n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels(treatments)\n",
        "    ax.set_xlabel('Weighted Score', fontsize=12)\n",
        "    ax.set_title('MCDA Score Breakdown by Criterion', fontsize=14, fontweight='bold')\n",
        "    ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=9)\n",
        "    ax.set_xlim(0, 110)\n",
        "    ax.grid(True, axis='x', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "fig = plot_stacked_contributions(mcda_results, weights, criteria)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_radar_chart(scored_df: pd.DataFrame, criteria_list: List[str]):\n",
        "    \"\"\"\n",
        "    Create radar/spider chart comparing treatments across criteria.\n",
        "    \"\"\"\n",
        "    treatments = scored_df['Treatment'].unique()\n",
        "    n_criteria = len(criteria_list)\n",
        "    \n",
        "    # Calculate angles\n",
        "    angles = np.linspace(0, 2 * np.pi, n_criteria, endpoint=False).tolist()\n",
        "    angles += angles[:1]  # Complete the loop\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(polar=True))\n",
        "    \n",
        "    colors = {'NEXONC': '#2ecc71', 'Standard Chemo': '#3498db', \n",
        "              'Best Supportive Care': '#e74c3c'}\n",
        "    \n",
        "    for treatment in treatments:\n",
        "        row = scored_df[scored_df['Treatment'] == treatment].iloc[0]\n",
        "        values = [row[c] for c in criteria_list]\n",
        "        values += values[:1]  # Complete the loop\n",
        "        \n",
        "        ax.plot(angles, values, 'o-', linewidth=2, \n",
        "                label=treatment, color=colors.get(treatment, 'gray'))\n",
        "        ax.fill(angles, values, alpha=0.15, color=colors.get(treatment, 'gray'))\n",
        "    \n",
        "    # Format\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels([c[:15] for c in criteria_list], fontsize=10)\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.set_title('Treatment Comparison Radar Chart', fontsize=14, \n",
        "                 fontweight='bold', pad=20)\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "fig = plot_radar_chart(scored_data, list(criteria.keys()))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation & Communication\n",
        "\n",
        "### Key Findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_mcda_interpretation(mcda_results: pd.DataFrame, \n",
        "                                 scenario_results: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Generate interpretation of MCDA results.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"MCDA INTERPRETATION\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    winner = mcda_results.iloc[0]\n",
        "    second = mcda_results.iloc[1]\n",
        "    \n",
        "    print(f\"\\n\u2705 PREFERRED TREATMENT: {winner['Treatment']}\")\n",
        "    print(f\"   Weighted Score: {winner['TOTAL SCORE']:.1f}/100\")\n",
        "    print(f\"   Lead over {second['Treatment']}: +{winner['TOTAL SCORE'] - second['TOTAL SCORE']:.1f} points\")\n",
        "    \n",
        "    # Robustness check\n",
        "    pivot = scenario_results.pivot(index='Scenario', columns='Treatment', values='Score')\n",
        "    winners = pivot.idxmax(axis=1)\n",
        "    winner_counts = winners.value_counts()\n",
        "    \n",
        "    print(\"\\n\ud83d\udcca ROBUSTNESS ANALYSIS\")\n",
        "    print(f\"   Scenarios tested: {len(pivot)}\")\n",
        "    for treatment, count in winner_counts.items():\n",
        "        pct = count / len(pivot) * 100\n",
        "        print(f\"   {treatment} preferred in: {count}/{len(pivot)} scenarios ({pct:.0f}%)\")\n",
        "    \n",
        "    # Key drivers\n",
        "    print(\"\\n\ud83d\udd11 KEY DRIVERS\")\n",
        "    print(\"   - NEXONC leads on survival endpoints (OS, PFS)\")\n",
        "    print(\"   - Higher toxicity partially offsets efficacy gains\")\n",
        "    print(\"   - QoL comparable to BSC despite treatment intensity\")\n",
        "    \n",
        "    print(\"\\n\u26a0\ufe0f  LIMITATIONS\")\n",
        "    print(\"   - Weights based on single stakeholder perspective\")\n",
        "    print(\"   - Simulated data for educational purposes only\")\n",
        "    print(\"   - Does not capture subgroup-specific benefit-risk\")\n",
        "\n",
        "generate_mcda_interpretation(mcda_results, scenario_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **MCDA explicitly integrates values** into benefit-risk through weights\n",
        "2. **Swing weighting** provides a structured approach to elicit preferences\n",
        "3. **Sensitivity analysis** tests robustness of conclusions\n",
        "4. **Multiple visualizations** serve different stakeholder needs\n",
        "\n",
        "### When to Use MCDA\n",
        "\n",
        "\u2705 Multiple stakeholders with different priorities  \n",
        "\u2705 Need to make value trade-offs explicit  \n",
        "\u2705 Regulatory submissions requiring quantitative B-R  \n",
        "\u2705 Integrating patient preferences  \n",
        "\n",
        "### Limitations\n",
        "\n",
        "\u26a0\ufe0f Requires agreement on criteria and scoring  \n",
        "\u26a0\ufe0f Weight elicitation can be challenging  \n",
        "\u26a0\ufe0f Linear scoring may oversimplify  \n",
        "\u26a0\ufe0f Results depend heavily on weights chosen  \n",
        "\n",
        "---\n",
        "\n",
        "### Further Reading\n",
        "\n",
        "- CIOMS Working Group XII Report, Chapter 5\n",
        "- Marsh K, et al. \"Multiple Criteria Decision Analysis for Health Care Decision Making\" Value Health 2014\n",
        "- EMA Benefit-Risk Methodology Project\n",
        "- NexVigilant Benefit-Risk Intelligence Toolkit (companion materials)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**NexVigilant** | *Empowerment Through Vigilance*\n",
        "\n",
        "This notebook is part of the [Benefit-Risk Intelligence Toolkit](https://github.com/nexvigilant/nv-BR-toolkit)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
